{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ef5ef2-e03b-45e3-9a05-f6d17d735229",
   "metadata": {},
   "source": [
    "## ISCX *Botnet* 2014 *Dataset*\n",
    "\n",
    "Este *dataset* foi retirado da página da unb.ca (University of New Brunswick): https://www.unb.ca/cic/datasets/botnet.html\n",
    "\n",
    "A informação que podemos obter é que se trata de uma junção de vários *datasets* sendo eles:\n",
    "- ISOT Dataset\n",
    "- ISCX 2012 IDS Dataset\n",
    "- Botnet traffic generated by the Malware Capture Facility Project\n",
    "\n",
    "### Informações do autor: \n",
    "O *dataset* de treino é composto por 43.92% de dados malignos e o *dataset* de teste é composto por 44.97% de dados malignos.\n",
    "\n",
    "---\n",
    "\n",
    "**No *dataset* de treino:**\n",
    "\n",
    "Botnet name | Type | Portion of flows in dataset\n",
    "\n",
    "    Neris                | IRC  | 21159  (12%)\n",
    "    Rbot                 | IRC  | 39316  (22%)\n",
    "    Virut                | HTTP | 1638   (0.94 %)\n",
    "    NSIS                 | P2P  | 4336   (2.48%)\n",
    "    SMTP Spam            | P2P  | 11296  (6.48%)\n",
    "    Zeus                 | P2P  | 31     (0.01%)\n",
    "    Zeus control (C & C) | P2P  | 20     (0.01%)\n",
    "\n",
    "--- \n",
    "\n",
    "**No *dataset* de teste:**\n",
    "\n",
    "Botnet name | Type | Portion of flows in dataset\n",
    "\n",
    "    Neris              | IRC  | 25967 (5.67%)\n",
    "    Rbot               | IRC  | 83    (0.018%)\n",
    "    Menti              | IRC  | 2878  (0.62%)\n",
    "    Sogou              | HTTP | 89    (0.019%)\n",
    "    Murlo              | IRC  | 4881  (1.06%)\n",
    "    Virut              | HTTP | 58576 (12.80%)\n",
    "    NSIS               | P2P  | 757   (0.165%)\n",
    "    Zeus               | P2P  | 502   (0.109%)\n",
    "    SMTP Spam          | P2P  | 21633 (4.72%)\n",
    "    UDP Storm          | P2P  | 44062 (9.63%)\n",
    "    Tbot               | IRC  | 1296  (0.283%)\n",
    "    Zero Access        | P2P  | 1011  (0.221%)\n",
    "    Weasel             | P2P  | 42313 (9.25%)\n",
    "    Smoke Bot          | P2P  | 78    (0.017%)\n",
    "    Zeus Control (C&C) | P2P  | 31    (0.006%)\n",
    "    ISCX IRC bot       | P2P  | 1816  (0.387%)\n",
    "\n",
    "---\n",
    "\n",
    "**IPs malignos:**\n",
    "\n",
    "    IRC\n",
    "        192.168.2.112 -> 131.202.243.84\n",
    "        192.168.5.122 -> 198.164.30.2\n",
    "        192.168.2.110 -> 192.168.5.122\n",
    "        192.168.4.118 -> 192.168.5.122\n",
    "        192.168.2.113 -> 192.168.5.122\n",
    "        192.168.1.103 -> 192.168.5.122\n",
    "        192.168.4.120 -> 192.168.5.122\n",
    "        192.168.2.112 -> 192.168.2.110\n",
    "        192.168.2.112 -> 192.168.4.120\n",
    "        192.168.2.112 -> 192.168.1.103\n",
    "        192.168.2.112 -> 192.168.2.113\n",
    "        192.168.2.112 -> 192.168.4.118\n",
    "        192.168.2.112 -> 192.168.2.109\n",
    "        192.168.2.112 -> 192.168.2.105\n",
    "        192.168.1.105 -> 192.168.5.122\n",
    "        \n",
    "    Neris: 147.32.84.180\n",
    "    RBot: 147.32.84.170\n",
    "    Menti: 147.32.84.150\n",
    "    Sogou: 147.32.84.140\n",
    "    Murlo: 147.32.84.130\n",
    "    Virut: 147.32.84.160\n",
    "    IRCbot and black hole1: 10.0.2.15\n",
    "    Black hole 2: 192.168.106.141\n",
    "    Black hole 3: 192.168.106.131\n",
    "    TBot: 172.16.253.130, 172.16.253.131, 172.16.253.129, 172.16.253.240\n",
    "    Weasel: Botmaster IP: 74.78.117.238; Bot IP: 158.65.110.24\n",
    "    Zeus (zeus sample 1 and 2 and 3, bin_zeus): 192.168.3.35, 192.168.3.25, 192.168.3.65, 172.29.0.116\n",
    "    Osx_trojan: 172.29.0.109\n",
    "    Zero access (zero access 1 and 2): 172.16.253.132, 192.168.248.165\n",
    "    Smoke bot: 10.37.130.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50b551-cd5f-4d3d-9f43-3b6b7cbfd694",
   "metadata": {},
   "source": [
    "### Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e976481-16a4-4a6b-ad3f-2280cd7ec8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor \n",
    "# Nova adição para feature engineering \n",
    "from scipy.stats import boxcox\n",
    "# Adição - métrica de avaliação de resultados Silhouette Score\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b0ebf-a4d5-4989-afcd-a675f89a4843",
   "metadata": {},
   "source": [
    "### Leitura de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6074166e-7466-4a7c-baf7-2582b59944b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar datasets\n",
    "df_train = pd.read_csv(r'X:\\Dissertacao\\python_projects\\dataset\\ISCX-Bot-2014\\ISCX_csv\\Testing_file.csv',\n",
    "                       encoding='ISO-8859-1')\n",
    "\n",
    "df_test = pd.read_csv(r'X:\\Dissertacao\\python_projects\\dataset\\ISCX-Bot-2014\\ISCX_csv\\Training_file.csv',\n",
    "                      encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7989680-2dfd-47f8-8ab3-4b29cdf3bee9",
   "metadata": {},
   "source": [
    "### Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ddc99d-2824-43f3-ae6b-fa2aacb936c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5114514 entries, 0 to 5114513\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   No.          int64  \n",
      " 1   Time         float64\n",
      " 2   Source       object \n",
      " 3   Destination  object \n",
      " 4   Protocol     object \n",
      " 5   Length       int64  \n",
      " 6   Info         object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 273.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Time</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Length</th>\n",
       "      <th>Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ethernet</td>\n",
       "      <td>60</td>\n",
       "      <td>[Packet size limited during capture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.985427</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>348</td>\n",
       "      <td>DHCP Discover - Transaction ID 0x6145b920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.985565</td>\n",
       "      <td>10.0.2.2</td>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>590</td>\n",
       "      <td>DHCP Offer    - Transaction ID 0x6145b920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.985927</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>373</td>\n",
       "      <td>DHCP Request  - Transaction ID 0x6145b920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.985998</td>\n",
       "      <td>10.0.2.2</td>\n",
       "      <td>10.0.2.15</td>\n",
       "      <td>DHCP</td>\n",
       "      <td>590</td>\n",
       "      <td>DHCP ACK      - Transaction ID 0x6145b920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.      Time    Source      Destination  Protocol  Length  \\\n",
       "0    1  0.000000       NaN              NaN  Ethernet      60   \n",
       "1    2  6.985427   0.0.0.0  255.255.255.255      DHCP     348   \n",
       "2    3  6.985565  10.0.2.2        10.0.2.15      DHCP     590   \n",
       "3    4  6.985927   0.0.0.0  255.255.255.255      DHCP     373   \n",
       "4    5  6.985998  10.0.2.2        10.0.2.15      DHCP     590   \n",
       "\n",
       "                                        Info  \n",
       "0       [Packet size limited during capture]  \n",
       "1  DHCP Discover - Transaction ID 0x6145b920  \n",
       "2  DHCP Offer    - Transaction ID 0x6145b920  \n",
       "3  DHCP Request  - Transaction ID 0x6145b920  \n",
       "4  DHCP ACK      - Transaction ID 0x6145b920  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d311ab-98bf-4a04-a5e8-7e21c8bce048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9388270 entries, 0 to 9388269\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   No.          int64  \n",
      " 1   Time         float64\n",
      " 2   Source       object \n",
      " 3   Destination  object \n",
      " 4   Protocol     object \n",
      " 5   Length       int64  \n",
      " 6   Info         object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 501.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Time</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Length</th>\n",
       "      <th>Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Cisco_db:19:c3</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>ARP</td>\n",
       "      <td>60</td>\n",
       "      <td>Who has 147.32.84.165? Tell 147.32.84.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.982709</td>\n",
       "      <td>Cisco_db:19:c3</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>ARP</td>\n",
       "      <td>60</td>\n",
       "      <td>Who has 147.32.84.165? Tell 147.32.84.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.099564</td>\n",
       "      <td>Cisco_db:19:c3</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>ARP</td>\n",
       "      <td>60</td>\n",
       "      <td>Who has 147.32.84.165? Tell 147.32.84.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50.369266</td>\n",
       "      <td>54:52:00:00:00:01</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>ARP</td>\n",
       "      <td>60</td>\n",
       "      <td>Who has 147.32.84.165? Tell 147.32.84.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>51.369054</td>\n",
       "      <td>54:52:00:00:00:01</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>ARP</td>\n",
       "      <td>60</td>\n",
       "      <td>Who has 147.32.84.165? Tell 147.32.84.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.       Time             Source Destination Protocol  Length  \\\n",
       "0    1   0.000000     Cisco_db:19:c3   Broadcast      ARP      60   \n",
       "1    2   8.982709     Cisco_db:19:c3   Broadcast      ARP      60   \n",
       "2    3  50.099564     Cisco_db:19:c3   Broadcast      ARP      60   \n",
       "3    4  50.369266  54:52:00:00:00:01   Broadcast      ARP      60   \n",
       "4    5  51.369054  54:52:00:00:00:01   Broadcast      ARP      60   \n",
       "\n",
       "                                       Info  \n",
       "0   Who has 147.32.84.165? Tell 147.32.84.1  \n",
       "1   Who has 147.32.84.165? Tell 147.32.84.1  \n",
       "2   Who has 147.32.84.165? Tell 147.32.84.1  \n",
       "3  Who has 147.32.84.165? Tell 147.32.84.85  \n",
       "4  Who has 147.32.84.165? Tell 147.32.84.85  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71882a0c-349a-4141-aa21-e84e55a52db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos encontrados nos pacotes de Treino:\n",
      " No.               0\n",
      "Time              0\n",
      "Source            1\n",
      "Destination       1\n",
      "Protocol          0\n",
      "Length            0\n",
      "Info           3898\n",
      "dtype: int64\n",
      "Valores nulos encontrados nos pacotes de Teste:\n",
      " No.                0\n",
      "Time               0\n",
      "Source             0\n",
      "Destination        0\n",
      "Protocol           0\n",
      "Length             0\n",
      "Info           49110\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores nulos encontrados nos pacotes de Treino:\\n\",df_train.isnull().sum())  \n",
    "print(\"Valores nulos encontrados nos pacotes de Teste:\\n\",df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac46b22-e529-4eb5-8021-3d6e7989a9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5.114514e+06\n",
      "mean     1.284569e+09\n",
      "std      4.879074e+07\n",
      "min      0.000000e+00\n",
      "25%      1.276250e+09\n",
      "50%      1.276579e+09\n",
      "75%      1.313450e+09\n",
      "max      1.359942e+09\n",
      "Name: Time, dtype: float64\n",
      "Valores de Tempo negativo nos pacotes de Treino:  0\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Time'].describe())  \n",
    "print(\"Valores de Tempo negativo nos pacotes de Treino: \", (df_train['Time'] < 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e48206a-2bc8-45d6-bd5d-cc4a4c68ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9.388270e+06\n",
      "mean    -4.999973e+07\n",
      "std      3.936417e+07\n",
      "min     -1.211172e+08\n",
      "25%     -3.664793e+07\n",
      "50%     -3.662771e+07\n",
      "75%     -3.659487e+07\n",
      "max      7.802317e+05\n",
      "Name: Time, dtype: float64\n",
      "Valores de Tempo negativo nos pacotes de Teste:  8171941\n"
     ]
    }
   ],
   "source": [
    "print(df_test['Time'].describe())  \n",
    "print(\"Valores de Tempo negativo nos pacotes de Teste: \", (df_test['Time'] < 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef005a0-b310-4c68-b2b5-d2d396df72b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocolos encontrados no conjunto de Treino:\n",
      "['Ethernet' 'DHCP' 'ARP' 'SSDP' 'ICMP' 'IGMPv3' 'NBNS' 'BROWSER' 'DNS'\n",
      " 'TCP' 'HTTP' 'NBSS' 'SMB' 'LANMAN' 'DCERPC' 'SRVSVC' 'WKSSVC' 'SPOOLSS'\n",
      " 'SMB Pipe' 'UDP' 'SSLv2' 'IRC' 'TLSv1' 'SNMP' 'SMTP' 'SMTP/IMF' 'SSLv3'\n",
      " 'NTP' 'HTTP/JSON' 'IPv4' 'SSH' 'PKIX-CRL' 'RDP' 'COTP' 'T.125' 'HTTP/XML'\n",
      " 'CLASSIC-STUN' 'IOXIDResolver' 'ISystemActivator' 'X11' 'RTCP' 'SSL'\n",
      " 'SIP' 'DB-LSP-DISC/JSON' 'ICMPv6' 'LLMNR' 'UDP/XML' 'DHCPv6' 'STP'\n",
      " 'RIPv2' '0x0000' 'DB-LSP-DISC' '0x0700' 'LLDP' 'IPX SAP' 'NBDS' 'SRVLOC'\n",
      " 'BOOTP' '0xffff' 'MDNS' 'IGMPv1' '0x4b0d' '0x4000' 'LLC' '0xe000' 'SSHv2'\n",
      " '0x3339' 'IGMPv2' 'IPv6' 'DTLS' 'eDonkey' 'ALLJOYN-NS'\n",
      " 'openSAFETY over UDP' '0x2aa1' 'ECMP' 'TCP, HiPerConTracer' 'H1'\n",
      " 'BitTorrent' 'SIGCOMP' 'MSMMS' 'TRDP' 'QUAKEWORLD' 'ECHO' 'H.225.0'\n",
      " 'GPRS-NS' '5co-legacy' 'UDP, HiPerConTracer' 'WSP' 'QUAKE3' '0xc8d8'\n",
      " 'VxLAN' '0xb0c8' '0x9cb1' '0x33a5' 'MSNMS' 'FIND' 'CIP I/O' 'POP'\n",
      " 'POP/IMF' 'BT-DHT' 'LSD' 'WireGuard' 'FTP' 'FTP-DATA' 'IMAP' 'KDP'\n",
      " 'BT-Tracker' 'IMAP/IMF' 'ID3v1']\n",
      "\n",
      "Protocolos encontrados no conjunto de Teste:\n",
      "['ARP' 'NBNS' 'DNS' 'TCP' 'HTTP' 'BROWSER' 'IGMPv3' 'SSDP' 'NBSS' 'SMB'\n",
      " 'LANMAN' 'SSL' 'IRC' 'HTTP/XML' 'PKTC' 'SMTP' 'ICMP' 'SMTP/IMF'\n",
      " 'PKIX-CRL' 'SSLv2' 'TLSv1' 'DCERPC' 'SIP' 'UDP' 'SNMP'\n",
      " 'TCP, HiPerConTracer' 'NTP' 'RDP' 'COTP' 'T.125' 'SSH' 'IPv4' 'SSLv3'\n",
      " 'BT-DHT' 'ANSI C12.22' 'UDP, HiPerConTracer' 'BAT_VIS' 'QUAKEWORLD'\n",
      " 'RSIP' 'IPv6' 'BFD Echo' 'QUAKE' 'eDonkey' 'MSNMS' 'QUAKE3' 'Pathport'\n",
      " 'WireGuard' 'CLASSIC-STUN' 'H1' 'Gnutella' 'MSMMS' 'MINT' 'VNC' 'ESP'\n",
      " 'X11' 'BitTorrent' 'SIGCOMP' 'LLC' 'TRDP' 'ECHO' 'H.225.0' 'GSMTAP'\n",
      " 'GPRS-NS' 'RTCP' '5co-legacy' 'ECMP' 'LLMNR' 'WSP' 'SSHv2' 'IMAP' 'MDNS'\n",
      " 'DHCP' 'POP' 'IMAP/IMF' 'DHCPv6' 'FTP' 'FTP-DATA' 'ICMPv6' 'FTP-DATA/XML'\n",
      " 'ID3v1' 'HTTP/JSON']\n"
     ]
    }
   ],
   "source": [
    "print(\"Protocolos encontrados no conjunto de Treino:\")\n",
    "print(df_train[\"Protocol\"].unique())\n",
    "# ________________________________ #\n",
    "print(\"\\nProtocolos encontrados no conjunto de Teste:\")\n",
    "print(df_test[\"Protocol\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd00f88-8708-49b6-8443-da99914616bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas estatísticas do tamanho de pacotes de Treino:\n",
      "count    5.114514e+06\n",
      "mean     4.545508e+02\n",
      "std      1.057905e+03\n",
      "min      4.200000e+01\n",
      "25%      6.000000e+01\n",
      "50%      6.700000e+01\n",
      "75%      6.240000e+02\n",
      "max      6.523800e+04\n",
      "Name: Length, dtype: float64\n",
      "============================\n",
      "Medidas estatísticas do tamanho de pacotes de Teste:\n",
      "count    9.388270e+06\n",
      "mean     5.448353e+02\n",
      "std      6.522112e+02\n",
      "min      5.400000e+01\n",
      "25%      6.000000e+01\n",
      "50%      9.600000e+01\n",
      "75%      1.434000e+03\n",
      "max      1.903400e+04\n",
      "Name: Length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Valores estatísticos do tamanho dos pacotes\n",
    "print(\"Medidas estatísticas do tamanho de pacotes de Treino:\")\n",
    "print(df_train['Length'].describe())  # Min, max, mean, etc.\n",
    "\n",
    "print(\"============================\")\n",
    "\n",
    "print(\"Medidas estatísticas do tamanho de pacotes de Teste:\")\n",
    "print(df_test['Length'].describe())  # Min, max, mean, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666751a-63ab-4a1c-952f-836509553216",
   "metadata": {},
   "source": [
    "### Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c7e8af-3da8-4b94-84ef-574bbfa72618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores NaN com \"Unknown\" em Info e remover valores NaN em Source e Destination\n",
    "df_train.fillna({\"Info\": \"Unknown\"}, inplace=True)\n",
    "df_test.fillna({\"Info\": \"Unknown\"}, inplace=True)\n",
    "df_train.dropna(subset=['Source', 'Destination'], inplace=True)\n",
    "df_test.dropna(subset=['Source', 'Destination'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f887ff82-55bb-40a5-b695-85346a0678c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter features categóricas (strings e objetos) em atributos numéricos \n",
    "df_train['Protocol'] = df_train['Protocol'].astype('category').cat.codes\n",
    "df_train['Source'] = df_train['Source'].astype('category').cat.codes\n",
    "df_train['Destination'] = df_train['Destination'].astype('category').cat.codes\n",
    "\n",
    "df_test['Protocol'] = df_test['Protocol'].astype('category').cat.codes\n",
    "df_test['Source'] = df_test['Source'].astype('category').cat.codes\n",
    "df_test['Destination'] = df_test['Destination'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405ef53-f66c-4ac6-bd5a-15e2292d6e3a",
   "metadata": {},
   "source": [
    "### Engenharia de *Atributos*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee900fca-2fe3-4617-9061-3b147ecef70a",
   "metadata": {},
   "source": [
    "LOG - Iterações feitas durante o desenvolvimento: \n",
    "\n",
    "    . Time_Diff é computada por IP Origem em vez de globalmente \n",
    "\n",
    "    . versão anterior de Packet_Rate usava \".count() / (x.max() - x.min())\" que pode\n",
    "    ser sensível a outliers. Nova versão usa IQR para excluir outliers extremos.\n",
    "\n",
    "    . Inter-Arrival Time passa a usar média móvel em vez de estática (Melhor eficiência)\n",
    "\n",
    "    . Usar \"np.where\" em Burst_Rate para salvaguardar em caso de Inter-Arrival Time = 0.\n",
    "\n",
    "    . Features com transformada logarítmica desaparecem e usa-se BoxCox - melhor para dados com distorção.\n",
    "\n",
    "    . Usar trasformada logarítimica em Inter-Arrival e Burst_Rate para melhorar para reduzir\n",
    "    o nível de distorção dos dados e manter a distribuição dos dados estável (teste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7867c4d3-703b-44e3-89e9-efdd7c636599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================Time Diff Feature===================================================== #\n",
    "\n",
    "df_train['Time_Diff'] = df_train.groupby(\"Source\")['Time'].diff().fillna(df_train.groupby(\"Source\")['Time'].transform(\"mean\"))\n",
    "df_test['Time_Diff'] = df_test.groupby(\"Source\")['Time'].diff().fillna(df_test.groupby(\"Source\")['Time'].transform(\"mean\"))\n",
    "\n",
    "# =================================================Packet Rate Feature=================================================== #\n",
    "\n",
    "def packet_rate(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    x_clipped = np.clip(x, q1 - 1.5 * iqr, q3 + 1.5 * iqr)  # Cortar em vez de remover\n",
    "    return len(x_clipped) / (x_clipped.max() - x_clipped.min() + 1e-6)\n",
    "\n",
    "df_train['Packet_Rate'] = df_train.groupby(\"Source\")['Time'].transform(packet_rate)\n",
    "df_test['Packet_Rate'] = df_test.groupby(\"Source\")['Time'].transform(packet_rate)\n",
    "\n",
    "# =============================================Inter-Arrival Time Feature================================================ #\n",
    "# rolling = 10  - considera os 10 pacotes anteriores. Usar outros valores para ver o que é melhor \n",
    "\n",
    "df_train[\"Inter_Arrival_Time\"] = df_train.groupby(\"Source\")[\"Time_Diff\"].transform(lambda x: x.rolling(10, min_periods=1).mean())\n",
    "df_test[\"Inter_Arrival_Time\"] = df_test.groupby(\"Source\")[\"Time_Diff\"].transform(lambda x: x.rolling(10, min_periods=1).mean())\n",
    "\n",
    "df_train[\"Inter_Arrival_Time\"] = df_train[\"Inter_Arrival_Time\"].clip(lower=1e-6) # para resolver problemas com valores negativos\n",
    "df_test[\"Inter_Arrival_Time\"] = df_test[\"Inter_Arrival_Time\"].clip(lower=1e-6)\n",
    "\n",
    "df_train[\"Log_IATime\"] = np.log1p(df_train[\"Inter_Arrival_Time\"])\n",
    "df_test[\"Log_IATime\"] = np.log1p(df_test[\"Inter_Arrival_Time\"])\n",
    "\n",
    "# =================================================Burst Rate Feature==================================================== #\n",
    "\n",
    "df_train[\"Burst_Rate\"] = np.where(df_train[\"Inter_Arrival_Time\"] > 1e-6, 1 / df_train[\"Inter_Arrival_Time\"], 0)\n",
    "df_test[\"Burst_Rate\"] = np.where(df_test[\"Inter_Arrival_Time\"] > 1e-6, 1 / df_test[\"Inter_Arrival_Time\"], 0)\n",
    "\n",
    "df_train[\"Burst_Rate\"] = df_train[\"Burst_Rate\"].clip(lower=1e-6) # para resolver problemas com valores negativos\n",
    "df_test[\"Burst_Rate\"] = df_test[\"Burst_Rate\"].clip(lower=1e-6)\n",
    "\n",
    "df_train[\"Log_BRate\"] = np.log1p(df_train[\"Burst_Rate\"])\n",
    "df_test[\"Log_BRate\"] = np.log1p(df_test[\"Burst_Rate\"])\n",
    "\n",
    "# =================================================BoxCox Features======================================================= #\n",
    "# Antes: Log_Length\n",
    "df_train[\"BoxCox_Length\"], _ = boxcox(df_train[\"Length\"] + 1e-3) # leve desvio \n",
    "df_test[\"BoxCox_Length\"], _ = boxcox(df_test[\"Length\"] + 1e-3)\n",
    "# Antes: Log_Packet_Length\n",
    "df_train[\"BoxCox_PRate\"], _ = boxcox(df_train[\"Packet_Rate\"] + 1)\n",
    "df_test[\"BoxCox_PRate\"], _ = boxcox(df_test[\"Packet_Rate\"] + 1)\n",
    "\n",
    "# ======================================================================================================================= #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3adc0e-c0c1-4c00-b5c9-b65fbdb78880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalonamento\n",
    "features = [\"Time_Diff\", \"Log_IATime\", \"Log_BRate\", \"BoxCox_Length\", \"BoxCox_PRate\"]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train[features])\n",
    "df_train_scaled = pd.DataFrame(scaler.transform(df_train[features]), columns=features)\n",
    "df_test_scaled = pd.DataFrame(scaler.transform(df_test[features]), columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c1972a-6223-4571-aa56-3ea3ad9a745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipular valores duplicados (problemas anteriores com duplicação de valores)\n",
    "\n",
    "df_train_scaled = df_train_scaled.drop_duplicates()\n",
    "df_test_scaled = df_test_scaled.drop_duplicates()\n",
    "\n",
    "# adicionar ruído para tratar valores muito idênticos \n",
    "df_train_scaled += np.random.normal(0, 1e-6, df_train_scaled.shape)\n",
    "df_test_scaled += np.random.normal(0, 1e-6, df_test_scaled.shape)\n",
    "\n",
    "# reduzir precisão (motivos de recursos computacionais)\n",
    "df_train_scaled = df_train_scaled.astype(\"float32\")\n",
    "df_test_scaled = df_test_scaled.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8007c8-31c8-4490-850b-29101e3c6ef8",
   "metadata": {},
   "source": [
    "### Treinar primeiro modelo (*Isolation Forest*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d29e25-933f-4a34-b120-736b511a0711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalias encontradas na fase de Treino: 15.72%\n",
      "Anomalias encontradas na fase de Teste: 33.71%\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest (IForest)\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=500,\n",
    "    contamination=\"auto\",\n",
    "    random_state=50,\n",
    "    verbose=0) \n",
    "\n",
    "iso_forest.fit(df_train_scaled)\n",
    "df_train_scaled[\"Anomaly_IForest\"] = iso_forest.predict(df_train_scaled)\n",
    "df_test_scaled[\"Anomaly_IForest\"] = iso_forest.predict(df_test_scaled)\n",
    "\n",
    "print(f\"Anomalias encontradas na fase de Treino: {(df_train_scaled['Anomaly_IForest'] == -1).sum() / len(df_train_scaled) * 100:.2f}%\")\n",
    "print(f\"Anomalias encontradas na fase de Teste: {(df_test_scaled['Anomaly_IForest'] == -1).sum() / len(df_test_scaled) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8ae5c-74a9-4eed-a643-989ac7d69035",
   "metadata": {},
   "source": [
    "### Treinar segundo modelo (OCSVM, AutoEncoder, -> LOF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00dbef-2e79-4021-baed-286a8e23200c",
   "metadata": {},
   "source": [
    "CONSIDERAÇÕES:\n",
    "\n",
    "n_neighbors:\n",
    "quanto maior o valor da vizinhança, maior o consumo de memória. \n",
    "Este consumo pode crescer rapidamente, ainda mais com o uso de muitos dados,\n",
    "então usamos apenas uma amostra dos dados, para treinar o algoritmo e não \n",
    "usar tanto poder computacional.\n",
    "    \n",
    "    -> usar valores altos se anomalias forem dispersas globalmente, e valores baixos se anomalias forem densas localmente\n",
    "    -> experimentar: 30, 50 (default), 100, *150*\n",
    "\n",
    "metrics: \n",
    "\n",
    "    euclidean- default, \n",
    "    \n",
    "    chebyshev - network logs, \n",
    "    \n",
    "    manhattan - packet-based data\n",
    "\n",
    "* Aumenta 10% por cada vez que aumenta 'contamination':\n",
    "  \n",
    "    -> 0.1 - 10%, 0.2 - 20%, 0.3 - 30% ...\n",
    "  \n",
    "  Usei \"auto\" para não forçar anomalias.\n",
    "\n",
    "  * melhor métrica: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8635be77-9964-471b-84de-981eee0b5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier Factor (LOF)\n",
    "batch_size = 200_000\n",
    "\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=45,\n",
    "    algorithm=\"ball_tree\", # a usar: \"ball_tree\" ou \"kd_tree\". Algoritmos de pesquisa k-NN\n",
    "    leaf_size=55, # valores mais baixos são mais preciso, mas demoram mais tempo para terminar\n",
    "    contamination=\"auto\", \n",
    "    metric=\"manhattan\",\n",
    "    #novelty=False,\n",
    "    n_jobs=-1)\n",
    "\n",
    "def lof_predict(data, batch_size, lof_model):\n",
    "    \n",
    "    y_pred = np.zeros(len(data))\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i + batch_size]  \n",
    "        y_pred[i:i + batch_size] = lof_model.fit_predict(batch) \n",
    "\n",
    "    return y_pred\n",
    "\n",
    "df_train_scaled['Anomaly_LOF'] = lof_predict(df_train_scaled, batch_size, lof)\n",
    "df_test_scaled['Anomaly_LOF'] = lof_predict(df_test_scaled, batch_size, lof)\n",
    "\n",
    "print(f\"Anomalias encontradas na fase de Treino: {(df_train_scaled['Anomaly_LOF'] == -1).sum() / len(df_train_scaled) * 100:.2f}%\")\n",
    "print(f\"Anomalias encontradas na fase de Teste: {(df_test_scaled['Anomaly_LOF'] == -1).sum() / len(df_test_scaled) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b85d13-8ec9-4d76-8576-aeebf879d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nível de concordância entre os modelos\n",
    "\n",
    "overlap = (df_train_scaled[\"Anomaly_LOF\"] == df_train_scaled[\"Anomaly_IForest\"]).mean()\n",
    "print(f\"Concordância entre algoritmos: LOF/I-Forest: {overlap:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805b3c6-e8ea-474d-834b-863c3ea8ddbb",
   "metadata": {},
   "source": [
    "### Visualização gráfica dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e8877-7022-4999-bb2d-3af08d2e7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de distribuição de features,ç\n",
    "features = df_train_scaled.columns[:-1]  # Exclui rótulos de anomalias\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.histplot(df_train_scaled[feature], bins=50, kde=True)\n",
    "    plt.title(f\"Histograma: {feature}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca939012-660d-42b6-8073-83ac22102883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa de correlação\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_train_scaled.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title(\"Mapa de Correlação dos Atributos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe3eaf-5b41-4ccb-b188-f5b379d72155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como há atributos muito semelhantes como visto no mapa de correlação\n",
    "# escolheu-se apenas aqueles que se apresentam distintos entre si. \n",
    "\n",
    "selected_features = [\"Log_IATime\", \"Log_BRate\", \"BoxCox_Length\"]\n",
    "\n",
    "fig, axes = plt.subplots(len(selected_features), 2, figsize=(14, 5 * len(selected_features)))\n",
    "\n",
    "for i, feature in enumerate(selected_features):\n",
    "    # Isolation Forest KDE\n",
    "    sns.kdeplot(df_train_scaled[df_train_scaled[\"Anomaly_IForest\"] == 1][feature], \n",
    "                label=\"Normal\", color=\"black\", ax=axes[i, 0], fill=True)\n",
    "    sns.kdeplot(df_train_scaled[df_train_scaled[\"Anomaly_IForest\"] == -1][feature], \n",
    "                label=\"Anomalia\", color=\"red\", ax=axes[i, 0], fill=True)\n",
    "    axes[i, 0].set_title(f\"KDE Plot - IForest <{feature}>\")\n",
    "    axes[i, 0].legend()\n",
    "    \n",
    "    # Local Outlier Factor KDE\n",
    "    sns.kdeplot(df_train_scaled[df_train_scaled[\"Anomaly_LOF\"] == 1][feature], \n",
    "                label=\"Normal\", color=\"black\", ax=axes[i, 1], fill=True)\n",
    "    sns.kdeplot(df_train_scaled[df_train_scaled[\"Anomaly_LOF\"] == -1][feature], \n",
    "                label=\"Anomalia\", color=\"red\", ax=axes[i, 1], fill=True)\n",
    "    axes[i, 1].set_title(f\"KDE Plot - LOF <{feature}>\")\n",
    "    axes[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647525a-285b-4bcf-b05f-ddc6e45b2f13",
   "metadata": {},
   "source": [
    "### Métrica de avaliação de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3112e8f-8831-4212-bed6-a81eadaf6c0b",
   "metadata": {},
   "source": [
    "#### Silhouette Score\n",
    " * **Como funciona:**\n",
    "   \n",
    "    -> Para cada ponto no dataset\n",
    "   \n",
    "   calcula a distância ao seu cluster (coesão).\n",
    "   \n",
    "   calcula a distância aos outros clusters (distinção)\n",
    "\n",
    "    -> Funciona no intervalo de -1 a 1\n",
    "\n",
    "   -1 é péssima distinção.\n",
    "   \n",
    "   0 é porque existe sobreposição de valores.\n",
    "   \n",
    "   1 é perfeita distinção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfa27d-4325-493f-bdac-060c3497840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 40_000\n",
    "num_batches = len(df_train_scaled) // sample  # Número de partições\n",
    "\n",
    "# Listas\n",
    "sil_scores_if_train = []\n",
    "sil_scores_if_test = []\n",
    "sil_scores_lof_train = []\n",
    "sil_scores_lof_test = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    print(f\"A processar partição {i+1}/{num_batches}...\")\n",
    "\n",
    "    train_batch = df_train_scaled.iloc[i * sample : (i + 1) * sample]\n",
    "    test_batch = df_test_scaled.iloc[i * sample : (i + 1) * sample]\n",
    "\n",
    "    sil_scores_if_train.append(silhouette_score(train_batch, train_batch[\"Anomaly_IForest\"], metric=\"manhattan\"))\n",
    "    sil_scores_if_test.append(silhouette_score(test_batch, test_batch[\"Anomaly_IForest\"], metric=\"manhattan\"))\n",
    "\n",
    "    sil_scores_lof_train.append(silhouette_score(train_batch, train_batch[\"Anomaly_LOF\"], metric=\"manhattan\"))\n",
    "    sil_scores_lof_test.append(silhouette_score(test_batch, test_batch[\"Anomaly_LOF\"], metric=\"manhattan\"))\n",
    "\n",
    "# Médias\n",
    "avg_sil_if_train = np.mean(sil_scores_if_train)\n",
    "avg_sil_if_test = np.mean(sil_scores_if_test)\n",
    "avg_sil_lof_train = np.mean(sil_scores_lof_train)\n",
    "avg_sil_lof_test = np.mean(sil_scores_lof_test)\n",
    "\n",
    "print(f\"\\nAvaliação final:\")\n",
    "print(f\"I-Forest -> Train: {avg_sil_if_train:.4f}\")\n",
    "print(f\"I-Forest -> Test: {avg_sil_if_test:.4f}\")\n",
    "print(f\"LOF -> Train: {avg_sil_lof_train:.4f}\")\n",
    "print(f\"LOF -> Test: {avg_sil_lof_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd004780-40f1-4e52-a970-01747ed5561b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
