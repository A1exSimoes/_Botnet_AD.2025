{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d8d2a7-ca3a-4e95-8cbf-c1a0e423c500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 172\u001b[0m\n\u001b[0;32m    169\u001b[0m models \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m: rf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgb\u001b[39m\u001b[38;5;124m\"\u001b[39m: gb, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlsvc\u001b[39m\u001b[38;5;124m\"\u001b[39m: lsvc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m\"\u001b[39m: sgd}\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 172\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m weights \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\calibration.py:419\u001b[0m, in \u001b[0;36mCalibratedClassifierCV.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ensemble:\n\u001b[0;32m    418\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalibrated_classifiers_ \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_classifier_calibrator_pair\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     this_estimator \u001b[38;5;241m=\u001b[39m clone(estimator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\calibration.py:614\u001b[0m, in \u001b[0;36m_fit_classifier_calibrator_pair\u001b[1;34m(estimator, X, y, train, test, method, classes, sample_weight, fit_params)\u001b[0m\n\u001b[0;32m    611\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_indexing(X, train), _safe_indexing(y, train)\n\u001b[0;32m    612\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m _safe_indexing(X, test), _safe_indexing(y, test)\n\u001b[1;32m--> 614\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m predictions, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[0;32m    617\u001b[0m     estimator,\n\u001b[0;32m    618\u001b[0m     X_test,\n\u001b[0;32m    619\u001b[0m     response_method\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecision_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    620\u001b[0m )\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;66;03m# Reshape binary output from `(n_samples,)` to `(n_samples, 1)`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:321\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m    317\u001b[0m _dual \u001b[38;5;241m=\u001b[39m _validate_dual_parameter(\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, X\n\u001b[0;32m    319\u001b[0m )\n\u001b[1;32m--> 321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# and LogisticRegression but LogisticRegression sets a structured\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# `n_iter_` attribute with information about the underlying OvR fits\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# while LinearSVC/R only reports the maximum value.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m n_iter_\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1229\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1226\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1228\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[1;32m-> 1229\u001b[0m raw_coef_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mliblinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m n_iter_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import RobustScaler, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve, auc, f1_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# =========================\n",
    "# CONFIGURATION\n",
    "# =========================\n",
    "TRAIN_PATH = r'X:\\Dissertacao\\python_projects\\dataset\\ISCX-Bot-2014\\ISCX_csv\\Testing_file.csv'\n",
    "TEST_PATH  = r'X:\\Dissertacao\\python_projects\\dataset\\ISCX-Bot-2014\\ISCX_csv\\Training_file.csv'\n",
    "SAMPLE_SIZE = 300_000\n",
    "RANDOM_STATE = 42\n",
    "OUTPUT_SUMMARY = \"semi_supervised_ensemble_summary.json\"\n",
    "\n",
    "# =========================\n",
    "# HELPER FUNCTIONS\n",
    "# =========================\n",
    "def safe_boxcox(series):\n",
    "    arr = np.asarray(series.fillna(0.0).astype(float) + 1e-6)\n",
    "    try:\n",
    "        if np.any(arr <= 0):\n",
    "            arr = arr - arr.min() + 1e-6\n",
    "        out, _ = boxcox(arr + 1e-6)\n",
    "        return out\n",
    "    except Exception:\n",
    "        return np.log1p(arr)\n",
    "\n",
    "def safe_sample(df, n, seed=RANDOM_STATE):\n",
    "    if n >= len(df):\n",
    "        return df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    return df.sample(n=n, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "def ensure_numeric(df, cols):\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0.0)\n",
    "    return df\n",
    "\n",
    "def combined_map(train, test, col):\n",
    "    train[col] = train.get(col, \"\").astype(str)\n",
    "    test[col] = test.get(col, \"\").astype(str)\n",
    "    uniques = pd.unique(pd.concat([train[col], test[col]], axis=0))\n",
    "    mapping = {v: i for i, v in enumerate(uniques)}\n",
    "    train[col + \"_enc\"] = train[col].map(mapping).fillna(-1).astype(int)\n",
    "    test[col + \"_enc\"] = test[col].map(mapping).fillna(-1).astype(int)\n",
    "    return mapping\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "df_train = pd.read_csv(TRAIN_PATH, low_memory=False, encoding='ISO-8859-1')\n",
    "df_test  = pd.read_csv(TEST_PATH,  low_memory=False, encoding='ISO-8859-1')\n",
    "\n",
    "for df in (df_train, df_test):\n",
    "    if 'Info' in df.columns:\n",
    "        df['Info'] = df['Info'].fillna(\"Unknown\")\n",
    "    for col in ['Time', 'Source', 'Destination', 'Length']:\n",
    "        if col in df.columns:\n",
    "            df.dropna(subset=[col], inplace=True)\n",
    "\n",
    "combined_map(df_train, df_test, 'Protocol')\n",
    "combined_map(df_train, df_test, 'Source')\n",
    "combined_map(df_train, df_test, 'Destination')\n",
    "\n",
    "# =========================\n",
    "# FEATURE ENGINEERING\n",
    "# =========================\n",
    "def build_features(df):\n",
    "    df = df.copy()\n",
    "    src, dst = 'Source_enc', 'Destination_enc'\n",
    "    df['Time'] = pd.to_numeric(df.get('Time', 0), errors='coerce').fillna(0)\n",
    "    df['Length'] = pd.to_numeric(df.get('Length', 0), errors='coerce').fillna(0)\n",
    "    \n",
    "    df['Time_Diff'] = df.groupby(src)['Time'].diff().fillna(0)\n",
    "    df['Inter_Arrival_Time'] = df.groupby(src)['Time_Diff'].transform(lambda s: s.rolling(10, min_periods=1).mean()).fillna(0)\n",
    "    df['Burst_Rate'] = np.where(df['Inter_Arrival_Time'] > 1e-6, 1.0 / df['Inter_Arrival_Time'], 0)\n",
    "    df['Pkt_Per_Src'] = df.groupby(src)['Length'].transform('count').fillna(0)\n",
    "    df['Session_Dur_Src'] = df.groupby(src)['Time'].transform(lambda x: x.max() - x.min()).fillna(0)\n",
    "    df['Bytes_Per_Session_Src'] = df.groupby(src)['Length'].transform('sum').fillna(0)\n",
    "    df['Packets_Per_Session_Src'] = df['Pkt_Per_Src']\n",
    "    df['Length_Mean'] = df.groupby(src)['Length'].transform('mean').fillna(0)\n",
    "    df['Length_Std'] = df.groupby(src)['Length'].transform('std').fillna(0)\n",
    "    \n",
    "    df['BoxCox_Length'] = safe_boxcox(df['Length'])\n",
    "    df['Log_BRate'] = np.log1p(df['Burst_Rate'])\n",
    "    df['Log_IATime'] = np.log1p(df['Inter_Arrival_Time'])\n",
    "    df['Rate_to_Length'] = df['Burst_Rate'] / (df['BoxCox_Length'] + 1e-6)\n",
    "    df['IAT_to_Session'] = df['Inter_Arrival_Time'] / (df['Session_Dur_Src'] + 1e-6)\n",
    "    df['Burst_Variability'] = df['Burst_Rate'].rolling(5, min_periods=1).std().fillna(0)\n",
    "    df['Pkt_Rate_Change'] = df['Pkt_Per_Src'].diff().fillna(0)\n",
    "    \n",
    "    features = [\n",
    "        'Time_Diff', 'Log_BRate', 'Log_IATime', 'BoxCox_Length', 'Length_Mean', 'Length_Std',\n",
    "        'Pkt_Per_Src', 'Session_Dur_Src', 'Rate_to_Length', 'IAT_to_Session', \n",
    "        'Burst_Variability', 'Pkt_Rate_Change', 'Bytes_Per_Session_Src', 'Packets_Per_Session_Src'\n",
    "    ]\n",
    "    df = ensure_numeric(df, features)\n",
    "    return df, features\n",
    "\n",
    "df_train, features_train = build_features(df_train)\n",
    "df_test, features_test   = build_features(df_test)\n",
    "NUM_FEATURES = list(dict.fromkeys(features_train + features_test))\n",
    "\n",
    "df_train_sample = safe_sample(df_train, SAMPLE_SIZE)\n",
    "df_test_sample  = safe_sample(df_test, SAMPLE_SIZE)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(df_train_sample[NUM_FEATURES])\n",
    "X_train = pd.DataFrame(scaler.transform(df_train_sample[NUM_FEATURES]), columns=NUM_FEATURES)\n",
    "X_test = pd.DataFrame(scaler.transform(df_test_sample[NUM_FEATURES]), columns=NUM_FEATURES)\n",
    "\n",
    "# =========================\n",
    "# PSEUDO-LABELS (using heuristic thresholds)\n",
    "# =========================\n",
    "thresholds = {\n",
    "    \"Neris\": lambda df: (df[\"Burst_Rate\"] > df[\"Burst_Rate\"].quantile(0.9)) & (df[\"Pkt_Per_Src\"] > df[\"Pkt_Per_Src\"].quantile(0.8)),\n",
    "    \"Virut\": lambda df: (df[\"BoxCox_Length\"] > df[\"BoxCox_Length\"].quantile(0.8)),\n",
    "    \"Zeus\": lambda df: (df[\"Inter_Arrival_Time\"].between(df[\"Inter_Arrival_Time\"].quantile(0.05),\n",
    "                                                         df[\"Inter_Arrival_Time\"].quantile(0.6))),\n",
    "}\n",
    "\n",
    "def label_profiles(df):\n",
    "    df[\"Pred_Botnet_Profile\"] = \"Normal\"\n",
    "    for label, rule in thresholds.items():\n",
    "        mask = rule(df)\n",
    "        df.loc[mask, \"Pred_Botnet_Profile\"] = label\n",
    "    return df\n",
    "\n",
    "df_train_sample = label_profiles(df_train_sample)\n",
    "df_test_sample = label_profiles(df_test_sample)\n",
    "\n",
    "# =========================\n",
    "# SUPERVISED MODEL TRAINING\n",
    "# =========================\n",
    "X_train_sup, X_test_sup = X_train, X_test\n",
    "y_train_sup, y_test_sup = df_train_sample[\"Pred_Botnet_Profile\"], df_test_sample[\"Pred_Botnet_Profile\"]\n",
    "\n",
    "try:\n",
    "    sm = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_bal, y_bal = sm.fit_resample(X_train_sup, y_train_sup)\n",
    "except Exception:\n",
    "    X_bal, y_bal = X_train_sup, y_train_sup\n",
    "\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_bal, y_bal, test_size=0.2, random_state=RANDOM_STATE, stratify=y_bal)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, class_weight=\"balanced_subsample\", random_state=RANDOM_STATE, n_jobs=-1)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, subsample=0.8, random_state=RANDOM_STATE)\n",
    "lsvc_base = LinearSVC(C=0.5, class_weight='balanced', max_iter=5000, random_state=RANDOM_STATE)\n",
    "lsvc = CalibratedClassifierCV(lsvc_base, cv=3)\n",
    "sgd_base = SGDClassifier(loss='log_loss', penalty='elasticnet', alpha=1e-4, max_iter=1500, tol=1e-3, learning_rate='adaptive', random_state=RANDOM_STATE)\n",
    "sgd = CalibratedClassifierCV(sgd_base, cv=3)\n",
    "\n",
    "models = {\"rf\": rf, \"gb\": gb, \"lsvc\": lsvc, \"sgd\": sgd}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "weights = {}\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_val)\n",
    "    weights[name] = max(f1_score(y_val, preds, average=\"weighted\"), 1e-6)\n",
    "total = sum(weights.values())\n",
    "weights = {k: v/total for k, v in weights.items()}\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(k, v) for k, v in models.items()],\n",
    "    voting=\"soft\",\n",
    "    weights=list(weights.values()),\n",
    "    n_jobs=-1\n",
    ")\n",
    "ensemble.fit(X_bal, y_bal)\n",
    "\n",
    "# =========================\n",
    "# EVALUATION\n",
    "# =========================\n",
    "y_pred_ens = ensemble.predict(X_test_sup)\n",
    "print(\"=== Ensemble Report ===\")\n",
    "print(classification_report(y_test_sup, y_pred_ens, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(y_test_sup, y_pred_ens, labels=ensemble.classes_)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=ensemble.classes_, yticklabels=ensemble.classes_, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Ensemble\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# PRECISION-RECALL / ROC\n",
    "# =========================\n",
    "labels = sorted(list(pd.unique(y_test_sup)))\n",
    "y_test_bin = label_binarize(y_test_sup, classes=labels)\n",
    "y_score = ensemble.predict_proba(X_test_sup)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, lab in enumerate(labels):\n",
    "    prec, rec, _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    plt.plot(rec, prec, lw=2, label=f\"{lab} (AUPR={auc(rec, prec):.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, lab in enumerate(labels):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{lab} (AUC={auc(fpr, tpr):.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "summary = {\n",
    "    \"train_class_distribution\": dict(Counter(y_bal)),\n",
    "    \"test_class_distribution\": dict(Counter(y_test_sup)),\n",
    "    \"ensemble_weights\": weights,\n",
    "    \"ensemble_report\": classification_report(y_test_sup, y_pred_ens, output_dict=True, zero_division=0),\n",
    "    \"features_used\": NUM_FEATURES,\n",
    "}\n",
    "with open(OUTPUT_SUMMARY, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"Summary saved to {OUTPUT_SUMMARY}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
