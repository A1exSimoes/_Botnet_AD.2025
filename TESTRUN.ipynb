{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905d9c02-af2f-41d4-9b07-81de0f461fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidated_pipeline.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time, json\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c749db-bd6b-41f0-b9b5-81b5e6a9342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# 0. CONFIG\n",
    "# ------------------------- #\n",
    "TRAIN_PATH = r'X:\\Dissertacao\\python_projects\\dataset\\ISCX-Bot-2014\\ISCX_csv\\Testing_file.csv'\n",
    "TEST_PATH  = r'X:\\Dissertacao\\python_projects\\dataset\\ISCX-Bot-2014\\ISCX_csv\\Training_file.csv'\n",
    "RANDOM_STATE = 42\n",
    "LOF_BATCH = 200_000\n",
    "SIL_BATCH = 40_000\n",
    "\n",
    "# ------------------------- #\n",
    "# 1. LOAD DATA\n",
    "# ------------------------- #\n",
    "def load_datasets(train_path, test_path):\n",
    "    df_tr = pd.read_csv(train_path, encoding=\"ISO-8859-1\")\n",
    "    df_te = pd.read_csv(test_path, encoding=\"ISO-8859-1\")\n",
    "    return df_tr, df_te\n",
    "\n",
    "df_train, df_test = load_datasets(TRAIN_PATH, TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b047b5f-8708-4cfa-97bf-02cee5a87593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_4140\\3683054171.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Info\"].fillna(\"Unknown\", inplace=True)\n",
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_4140\\3683054171.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Info\"].fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- #\n",
    "# 2. BASIC CLEANING\n",
    "# ------------------------- #\n",
    "for df in [df_train, df_test]:\n",
    "    df[\"Info\"].fillna(\"Unknown\", inplace=True)\n",
    "    df.dropna(subset=[\"Source\",\"Destination\"], inplace=True)\n",
    "    df = df[df[\"Time\"] >= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1564fb3a-6ae3-41eb-9f8d-61373f2c1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# 3. SAFE CATEGORICAL ENCODING\n",
    "# ------------------------- #\n",
    "def build_mapping(train_col, test_col, name):\n",
    "    all_values = pd.concat([train_col, test_col]).unique()\n",
    "    mapping = {val: idx for idx, val in enumerate(all_values)}\n",
    "    with open(f\"{name}_mapping.json\",\"w\") as f: json.dump(mapping,f)\n",
    "    return mapping\n",
    "\n",
    "protocol_mapping = build_mapping(df_train[\"Protocol\"], df_test[\"Protocol\"], \"protocol\")\n",
    "df_train[\"Protocol_enc\"] = df_train[\"Protocol\"].map(protocol_mapping).fillna(-1).astype(int)\n",
    "df_test[\"Protocol_enc\"]  = df_test[\"Protocol\"].map(protocol_mapping).fillna(-1).astype(int)\n",
    "\n",
    "source_mapping = build_mapping(df_train[\"Source\"], df_test[\"Source\"], \"source\")\n",
    "df_train[\"Source_enc\"] = df_train[\"Source\"].map(source_mapping).fillna(-1).astype(int)\n",
    "df_test[\"Source_enc\"]  = df_test[\"Source\"].map(source_mapping).fillna(-1).astype(int)\n",
    "\n",
    "dest_mapping = build_mapping(df_train[\"Destination\"], df_test[\"Destination\"], \"destination\")\n",
    "df_train[\"Destination_enc\"] = df_train[\"Destination\"].map(dest_mapping).fillna(-1).astype(int)\n",
    "df_test[\"Destination_enc\"]  = df_test[\"Destination\"].map(dest_mapping).fillna(-1).astype(int)\n",
    "\n",
    "df_train.drop([\"Protocol\",\"Source\",\"Destination\"], axis=1, inplace=True)\n",
    "df_test.drop([\"Protocol\",\"Source\",\"Destination\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facb5a67-744a-4fbc-beb8-197732d5249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# 4. FEATURE ENGINEERING\n",
    "# ------------------------- #\n",
    "def build_features(df):\n",
    "    df[\"Time_Diff\"] = df.groupby(\"Source_enc\")[\"Time\"].diff()\n",
    "    df[\"Time_Diff\"] = df[\"Time_Diff\"].fillna(df.groupby(\"Source_enc\")[\"Time\"].transform(\"median\")).fillna(0.0)\n",
    "\n",
    "    def packet_rate(series):\n",
    "        if len(series)<2: return 0.0\n",
    "        span = series.max() - series.min()\n",
    "        return len(series)/(span+1e-6)\n",
    "    df[\"Packet_Rate\"] = df.groupby(\"Source_enc\")[\"Time\"].transform(packet_rate)\n",
    "\n",
    "    df[\"Inter_Arrival_Time\"] = df.groupby(\"Source_enc\")[\"Time_Diff\"].transform(lambda x: x.rolling(10,min_periods=1).mean())\n",
    "    df[\"Inter_Arrival_Time\"] = df[\"Inter_Arrival_Time\"].clip(lower=1e-6)\n",
    "\n",
    "    df[\"Burst_Rate\"] = np.where(df[\"Inter_Arrival_Time\"]>1e-6, 1/df[\"Inter_Arrival_Time\"], 0.0)\n",
    "\n",
    "    # variability features\n",
    "    df[\"Length_Mean\"] = df.groupby(\"Source_enc\")[\"Length\"].transform(\"mean\")\n",
    "    df[\"Length_Std\"]  = df.groupby(\"Source_enc\")[\"Length\"].transform(\"std\").fillna(0)\n",
    "    df[\"Pkt_Per_Src\"] = df.groupby(\"Source_enc\")[\"Length\"].transform(\"count\")\n",
    "\n",
    "    # transforms\n",
    "    df[\"Log_IATime\"] = np.log1p(df[\"Inter_Arrival_Time\"])\n",
    "    df[\"Log_BRate\"]  = np.log1p(df[\"Burst_Rate\"])\n",
    "    df[\"BoxCox_Length\"], _ = boxcox(df[\"Length\"]+1e-3)\n",
    "    try:\n",
    "        df[\"BoxCox_PRate\"], _ = boxcox(df[\"Packet_Rate\"]+1e-6)\n",
    "    except Exception:\n",
    "        df[\"BoxCox_PRate\"] = np.log1p(df[\"Packet_Rate\"])\n",
    "    return df\n",
    "\n",
    "df_train = build_features(df_train)\n",
    "df_test  = build_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f62ef4-1703-453e-999e-c0d7ebdd0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# 5. SCALE\n",
    "# ------------------------- #\n",
    "NUM_FEATURES = [\n",
    "    \"Time_Diff\",\"Log_IATime\",\"Log_BRate\",\n",
    "    \"BoxCox_Length\",\"BoxCox_PRate\",\n",
    "    \"Length_Mean\",\"Length_Std\",\"Pkt_Per_Src\"\n",
    "]\n",
    "scaler = MinMaxScaler().fit(df_train[NUM_FEATURES])\n",
    "df_train_scaled = pd.DataFrame(scaler.transform(df_train[NUM_FEATURES]), columns=NUM_FEATURES)\n",
    "df_test_scaled  = pd.DataFrame(scaler.transform(df_test[NUM_FEATURES]), columns=NUM_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf92705-ab66-4608-b767-240060c0e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# 6. ISOLATION FOREST\n",
    "# ------------------------- #\n",
    "iso = IsolationForest(n_estimators=500, contamination=\"auto\", random_state=RANDOM_STATE, verbose=0)\n",
    "iso.fit(df_train_scaled)\n",
    "df_train_scaled[\"Anomaly_IForest\"] = iso.predict(df_train_scaled)\n",
    "df_test_scaled[\"Anomaly_IForest\"]  = iso.predict(df_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e36464-d9cf-41bc-929b-90830187c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_lof.py:322: UserWarning: Duplicate values are leading to incorrect results. Increase the number of neighbors for more accurate results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- #\n",
    "# 7. LOF\n",
    "# ------------------------- #\n",
    "lof = LocalOutlierFactor(n_neighbors=30, contamination=\"auto\", metric=\"manhattan\", n_jobs=-1)\n",
    "def lof_predict_batched(X, batch=LOF_BATCH, lof_model=None):\n",
    "    if lof_model is None: lof_model=LocalOutlierFactor(n_neighbors=30)\n",
    "    y=np.zeros(len(X),dtype=int)\n",
    "    for i in range(0,len(X),batch):\n",
    "        y[i:i+batch]=lof_model.fit_predict(X.iloc[i:i+batch])\n",
    "    return y\n",
    "\n",
    "df_train_scaled[\"Anomaly_LOF\"] = lof_predict_batched(df_train_scaled)\n",
    "df_test_scaled[\"Anomaly_LOF\"]  = lof_predict_batched(df_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38a0830-fd7d-4473-ae17-64d756a800ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IForest train %: 11.984405944417386\n",
      "IForest test  %: 44.84624962852581\n",
      "LOF train %: 7.558725532616693\n",
      "LOF test  %: 7.731882444795474\n",
      "Silhouette IForest train: 0.4265220563175156\n",
      "Silhouette LOF train: 0.04784538270065358\n",
      "Silhouette IForest test: 0.355805462166546\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSilhouette LOF train:\u001b[39m\u001b[38;5;124m\"\u001b[39m,batched_silhouette(df_train_scaled,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_LOF\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSilhouette IForest test:\u001b[39m\u001b[38;5;124m\"\u001b[39m,batched_silhouette(df_test_scaled,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomaly_IForest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSilhouette LOF test:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mbatched_silhouette\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnomaly_LOF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mbatched_silhouette\u001b[1;34m(df, labels_col, batch)\u001b[0m\n\u001b[0;32m     13\u001b[0m     b\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b[labels_col]\u001b[38;5;241m.\u001b[39munique())\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m2\u001b[39m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mNUM_FEATURES\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores) \u001b[38;5;28;01mif\u001b[39;00m scores \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:139\u001b[0m, in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:303\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    299\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m    300\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    301\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[0;32m    302\u001b[0m )\n\u001b[1;32m--> 303\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m intra_clust_dists, inter_clust_dists \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    305\u001b[0m intra_clust_dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2252\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2251\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2252\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2254\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2256\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2258\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2480\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2478\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1973\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1970\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:388\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    384\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m         )\n\u001b[1;32m--> 388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:428\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    425\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    426\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n\u001b[1;32m--> 428\u001b[0m xp_zero \u001b[38;5;241m=\u001b[39m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m distances \u001b[38;5;241m=\u001b[39m _modify_in_place_if_numpy(\n\u001b[0;32m    430\u001b[0m     xp, xp\u001b[38;5;241m.\u001b[39mmaximum, distances, xp_zero, out\u001b[38;5;241m=\u001b[39mdistances\n\u001b[0;32m    431\u001b[0m )\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:401\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.asarray\u001b[1;34m(self, x, dtype, device, copy)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, dtype, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;66;03m# astype is not defined in the top level NumPy namespace\u001b[39;00m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[1;32m--> 401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21masarray\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     _check_device_cpu(device)\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# Support copy in NumPy namespace\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------- #\n",
    "# 8. METRICS & SILHOUETTE\n",
    "# ------------------------- #\n",
    "def anomaly_percent(df,col): return (df[col]==-1).sum()/len(df)*100\n",
    "print(\"IForest train %:\",anomaly_percent(df_train_scaled,\"Anomaly_IForest\"))\n",
    "print(\"IForest test  %:\",anomaly_percent(df_test_scaled,\"Anomaly_IForest\"))\n",
    "print(\"LOF train %:\",anomaly_percent(df_train_scaled,\"Anomaly_LOF\"))\n",
    "print(\"LOF test  %:\",anomaly_percent(df_test_scaled,\"Anomaly_LOF\"))\n",
    "\n",
    "def batched_silhouette(df,labels_col,batch=SIL_BATCH):\n",
    "    scores=[]\n",
    "    for i in range(0,len(df),batch):\n",
    "        b=df.iloc[i:i+batch]\n",
    "        if len(b[labels_col].unique())<2: continue\n",
    "        scores.append(silhouette_score(b[NUM_FEATURES], b[labels_col]))\n",
    "    return np.mean(scores) if scores else np.nan\n",
    "\n",
    "print(\"Silhouette IForest train:\",batched_silhouette(df_train_scaled,\"Anomaly_IForest\"))\n",
    "print(\"Silhouette LOF train:\",batched_silhouette(df_train_scaled,\"Anomaly_LOF\"))\n",
    "print(\"Silhouette IForest test:\",batched_silhouette(df_test_scaled,\"Anomaly_IForest\"))\n",
    "print(\"Silhouette LOF test:\",batched_silhouette(df_test_scaled,\"Anomaly_LOF\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10ab55-006f-422d-bd88-1e39916e6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# 9. PLOTS\n",
    "# ------------------------- #\n",
    "def feature_sensitivity(df,features,label_col):\n",
    "    res={}\n",
    "    for f in features:\n",
    "        mean_norm=df.loc[df[label_col]==1,f].mean()\n",
    "        mean_anom=df.loc[df[label_col]==-1,f].mean()\n",
    "        res[f]=mean_anom-mean_norm\n",
    "    return res\n",
    "\n",
    "for model in [\"IForest\",\"LOF\"]:\n",
    "    fs_train=feature_sensitivity(df_train_scaled,NUM_FEATURES,f\"Anomaly_{model}\")\n",
    "    fs_test =feature_sensitivity(df_test_scaled,NUM_FEATURES,f\"Anomaly_{model}\")\n",
    "    plt.figure(figsize=(8,5)); pd.Series(fs_train).sort_values().plot(kind=\"barh\",color=\"orange\"); plt.title(f\"{model} Train Feature Sensitivity\"); plt.show()\n",
    "    plt.figure(figsize=(8,5)); pd.Series(fs_test).sort_values().plot(kind=\"barh\",color=\"green\"); plt.title(f\"{model} Test Feature Sensitivity\"); plt.show()\n",
    "\n",
    "def kde_plots(df,features,label_col,model_name,dataset):\n",
    "    for f in features:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.kdeplot(df.loc[df[label_col]==1,f],label=\"Normal\",fill=True,color=\"blue\")\n",
    "        sns.kdeplot(df.loc[df[label_col]==-1,f],label=\"Anomaly\",fill=True,color=\"red\")\n",
    "        plt.title(f\"{model_name}-{dataset}-{f}\")\n",
    "        plt.legend(); plt.show()\n",
    "\n",
    "kde_plots(df_train_scaled,NUM_FEATURES,\"Anomaly_IForest\",\"IForest\",\"Train\")\n",
    "kde_plots(df_train_scaled,NUM_FEATURES,\"Anomaly_LOF\",\"LOF\",\"Train\")\n",
    "kde_plots(df_test_scaled,NUM_FEATURES,\"Anomaly_IForest\",\"IForest\",\"Test\")\n",
    "kde_plots(df_test_scaled,NUM_FEATURES,\"Anomaly_LOF\",\"LOF\",\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea625e78-583c-4c3d-a379-ab6b66d9c4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
